<!DOCTYPE html>
<html lang="cn">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimal-ui">
    <title>Collection</title>
    <style>
        @font-face {
	        font-family: Orbitron-Regular;
	        src: url(../font/Orbitron-Regular.ttf);
            }
        @font-face {
	        font-family: Orbitron-Bold;
	        src: url(../font/Orbitron-Bold.ttf);
            }
        @font-face {
	        font-family: Orbitron-Black;
	        src: url(../font/Orbitron-Black.ttf);
            }
        @font-face {
	        font-family: Orbitron-Medium;
	        src: url(../font/Orbitron-Medium.ttf);
            }
        @font-face {
	        font-family: Mono-Regular;
	        src: url(../font/FontsFree-Net-Mono-Regular.ttf);
            }
        @font-face {
	        font-family: Orbitron-Light;
	        src: url(../font/Orbitron-Light.ttf);
            }
        @font-face {
	        font-family: FiraCode-Regular;
	        src: url(../font/FiraCode-Regular.otf);
            }
    </style>
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/animate.css">
    <link rel="stylesheet" href="css/templatemo_style.css">
    <link rel="icon" href="./picture/favicon.ico">
    <script src="https://cdn.jsdelivr.net/npm/bluebird@3/js/browser/bluebird.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/whatwg-fetch@2.0.3/fetch.min.js"></script>
    <script src="https://cdn.staticfile.org/jquery/2.1.1/jquery.min.js"></script>
    <script src="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script>

    <!--End-->
    <script>
    fetch('https://v1.hitokoto.cn')
        .then(function (res){
        return res.json();
        })
        .then(function (data) {
        var hitokoto = document.getElementById('hitokoto');
        hitokoto.innerText = data.hitokoto;
        })
        .catch(function (err) {
        console.error(err);
        })
    </script>

</head>

<body oncontextmenu="return false" onselectstart="return false" ondragstart="return false">

<header class="site-header container animated fadeInDown">
    <div class="header-wrapper"></div>
</header>

<div id="menu-container">
    <div id="menu-1" class="homepage home-section container">
        <div class="home-intro text-center">
            <h2 class="welcome-title animated fadeInLeft">
                My Collection
                <p class="welcome-title animated fadeInRight">
                    Welcome to my collection room,<br/>
                    which used to record recent reading and learning.
                </p>
            </h2>
            <div style="border-bottom: 2px solid #46494f;"></div>

            <div class="Reading">
                <h2 class="animated fadeInLeft">Reading</h2>

                <ul class="animated fadeInRight">
                    <li>2022.08 - <a href="https://ieeexplore.ieee.org/document/9721002">Neither Fast nor Slow: How to Fly Through Narrow Tunnels.</a> </li>
                    <li>Luqi Wang; Hao Xu; Yichen Zhang; Shaojie Shen </li>
                </ul>
                <p class="animated fadeInLeft">
                    Abstract:<br/>
                    Nowadays, multirotors are playing important roles in abundant types of missions.
                    During these missions, entering confined and narrow tunnels that are barely accessible to humans is desirable yet extremely challenging for multirotors.
                    The restricted space and significant ego airflow disturbances induce control issues at both fast and slow flight speeds,
                    meanwhile bringing about problems in state estimation and perception.
                    Thus, a smooth trajectory at the proper speed is necessary for safe tunnel flights.
                    To address these challenges, in this letter,
                    a complete autonomous aerial system that can achieve smooth flights through tunnels with dimensions
                    as narrow as to 0.6 m is presented.
                    The system contains a motion planner that generates smooth mini-jerk trajectories along the tunnel center lines,
                    which are extracted according to the map and Euclidean distance field (EDF),
                    and its practical speed range is obtained through computational fluid dynamics (CFD) and flight data analyses.
                    Extensive flight experiments on the quadrotor are conducted inside multiple narrow tunnels to validate the planning framework as well as the robustness of the whole system.
                </p>
                <br /><br />

                <ul class="animated fadeInRight">
                    <li>2022.08 -
                        <a href="https://ieeexplore.ieee.org/document/9655477">
                            Semi-Supervised Learning: Structure, Reflectance and Lighting Estimation From a Night Image Pair.
                        </a>
                    </li>
                    <li>Ke Wang; Shaojie Shen </li>
                </ul>
                <p class="animated fadeInLeft">
                    Abstract:<br/>
                    While unsupervised approaches have been proposed to estimate reflectance and shading layers for images, the decomposition process is a challenging, under-determined inverse problem. Previous unsupervised approaches for intrinsic decomposition of images are strictly reliant on special image sequences, for example, image sequences for a fixed scene with changing illumination or multi-view images containing rich illumination variation. As an alternative to these unsupervised intrinsic decomposition methods, we propose a semi-supervised method. Our method adopts a simplified scene representation to greatly reduce the complexity of spatially varying lighting, which allows us to partially restore the lighting from a night image pair. Moreover, we design several novel unsupervised guiding losses, and the training data used in our method are easily collected by setting different exposure times for a standard stereo setup. We further demonstrate the effectiveness of the proposed method by quantitatively and qualitatively comparing our method with recent works on the modified MPI dataset and a collected highly dynamic dataset named NightCampus.
                </p>
                <br /><br />

                <ul class="animated fadeInRight">
                    <li>2022.08 -
                        <a href="https://arxiv.org/abs/2011.03993">
                           VID-Fusion: Robust Visual-Inertial-Dynamics Odometry for Accurate External Force Estimation
                        </a>
                    </li>
                    <li>Ke Wang; Shaojie Shen </li>
                </ul>
                <p class="animated fadeInLeft">
                    Abstract:<br/>
                    Recently, quadrotors are gaining significant attention in aerial transportation and delivery. In these scenarios, an accurate estimation of the external force is as essential as the 6 degree-of-freedom (DoF) pose since it is of vital importance for planning and control of the vehicle. To this end, we propose a tightly-coupled Visual-Inertial-Dynamics (VID) system that simultaneously estimates the external force applied to the quadrotor along with the 6 DoF pose. Our method builds on the state-of-the-art optimization-based Visual-Inertial system, with a novel deduction of the dynamics and external force factor extended from VIMO. Utilizing the proposed dynamics and external force factor, our estimator robustly and accurately estimates the external force even when it varies widely. Moreover, since we explicitly consider the influence of the external force, when compared with VIMO and VINS-Mono, our method shows comparable and superior pose accuracy, even when the external force ranges from neglectable to significant. The robustness and effectiveness of the proposed method are validated by extensive real-world experiments and application scenario simulation. We will release an open-source package of this method along with datasets with ground truth force measurements for the reference of the community.
                </p>
            </div>

            <div style="border-bottom: 2px solid #46494f;"></div>
            <br /><br />

            <div class="Learning">
                <h2 class="animated fadeInRight">Learning</h2>
            </div>

            <ul class="animated fadeInRight">
                <li>2022.08 - <a href="https://ieeexplore.ieee.org/document/9721002">SimGNN: A Neural Network Approach to Fast Graph Similarity Computation</a> </li>
                <li>Yunsheng Bai; Hao Ding; Song Bian; Ting Chen; Wei Wang </li>
            </ul>
            <p class="animated fadeInLeft">
            </p>
            <br /><br />
        </div>


        <div style="border-bottom: 2px solid #46494f;"></div>
        <br /><br />

        <footer>
            <div class="blog-header text-center">
                <div class="row">
                    <div class="col-md-12 copyright">
                        <p><a href="../index.html">Home</a></p>
                    </div>
                </div>
            </div>
        </footer>
    </div>
</div>
</div>
</body>
</html>
